{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15dfee56-18a3-4e47-9013-f5e939ef3bc7",
   "metadata": {},
   "source": [
    "# Forward Propagation: Understanding the Basics\n",
    "\n",
    "## **Introduction**\n",
    "**Forward Propagation** is the process by which input data passes through the layers of a neural network to produce an output. It involves two main steps:\n",
    "1. **Linear Transformation:** Computing the weighted sum of inputs and biases.\n",
    "2. **Activation Function:** Applying a non-linear function (e.g., sigmoid) to the result.\n",
    "\n",
    "In this notebook, we will implement forward propagation for a simple neural network with one hidden layer.\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Concepts**\n",
    "- **Input Layer:** Receives the input data.\n",
    "- **Hidden Layer:** Performs computations using weights and biases.\n",
    "- **Output Layer:** Produces the final output.\n",
    "- **Activation Function:** Introduces non-linearity into the model.\n",
    "\n",
    "---\n",
    "\n",
    "## **Implementation**\n",
    "Below is the Python code for implementing forward propagation in a neural network with one hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0dab7c6-8fa3-4430-9008-cb88d7056830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of the neural network:\n",
      "[[0.68751214]\n",
      " [0.74161628]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define a simple neural network with one hidden layer\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # Initialize weights and biases randomly\n",
    "        self.weights1 = np.random.randn(input_size, hidden_size)\n",
    "        self.bias1 = np.random.randn(hidden_size)\n",
    "        self.weights2 = np.random.randn(hidden_size, output_size)\n",
    "        self.bias2 = np.random.randn(output_size)\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        # Sigmoid activation function\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Forward propagation\n",
    "        self.z1 = np.dot(X, self.weights1) + self.bias1\n",
    "        self.a1 = self.sigmoid(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.weights2) + self.bias2\n",
    "        self.a2 = self.sigmoid(self.z2)\n",
    "        return self.a2\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Input data (2 samples, 3 features each)\n",
    "    X = np.array([[0, 0, 1], [1, 1, 1]])\n",
    "\n",
    "    # Create a neural network\n",
    "    nn = NeuralNetwork(input_size=3, hidden_size=4, output_size=1)\n",
    "\n",
    "    # Perform forward propagation\n",
    "    output = nn.forward(X)\n",
    "    print(\"Output of the neural network:\")\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d5107f-942f-4787-8a01-e6afb28a3413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
